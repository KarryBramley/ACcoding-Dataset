dataset:
  name: FB15k

training:
  epochs: 3 # Maximum number of training epochs
  graph_batch_size: 32  # Number of positive triples to sample during training
  sampling_method: edge-neighborhood  # Sampling method for randomly selecting positive triples
  negative_sampling:
    sampling_rate: 10  # Number of negative samples to produce per positive triple
    head_prob: 0.5  # Ratio of corrupting heads (i.e. 0.5 means corrupt 50% heads and 50% tails)
  optimiser:
    algorithm: adam
    weight_decay: 0.0
    learn_rate: 0.01
  use_weight: False
  use_cuda: True  # If true, model is trained on available GPUs.

encoder:
  model: rgcn
  num_layers: 1  # Number of graph convolution layers
  hidden1_size: 200  # Size of first hidden layer
  node_embedding: 200  # Size of node embedding
  decomposition:
    type: basis
    num_bases: 2
  edge_dropout:
    general: 0.5  # Dropout rate for all edges (except self-loops)
    self_loop: 0.2  # Dropout rate for self-loops
    self_loop_type: schlichtkrull-dropout
  weight_init: schlichtkrull-normal  # Weight Initialisation
  include_gain: False  # Add scaling factor depending on the type of non-linearity function used
  bias_init: zeros  # Bias Initialisation (Delete this line to remove biases)

decoder:
  model: dotmult
  l2_penalty_type: 'schlichtkrull-l2'
  l2_penalty: 0.01
  weight_init: standard-normal
  include_gain: False  # Add scaling factor depending on the type of non-linearity function used

evaluation:
  final_run: True  # If true, evaluates model on test set. Otherwise, validation set is used.
  filtered: True  # If true, reports filtered metrics. Otherwise, raw metrics are computed.
  check_every: 20  # Evaluate model at regular intervals (By default, every 2000 epochs)
  batch_size: 64  # Number of triples per evaluation batch
  verbose: True  # Show evaluation progress bar
